import os
from dotenv import load_dotenv
from openai import OpenAI
from LLM.LLMClient import LLMClient
_ = load_dotenv()

class OpenAIClient(LLMClient):
    def __init__(self, tools: list = None):
        """
        Initializes the OpenAIClient with the given PromptManager.
        """
        self.open_ai_key: str = os.getenv("OPENAI_API_KEY")
        if not self.open_ai_key:
            raise ValueError("OPENAI_API_KEY environment variable not set.")
        
        self.client: OpenAI = OpenAI(api_key=self.open_ai_key)
        self.tools = tools

    def generate_chat_response(self, messages: list, model: str = "gpt-5.1-nano") -> str:
        """
        Generates a completion using the OpenAI API based on the user input.

        Args:
            user_input (str): The input provided by the user.

        Returns:
            str: The response generated by the OpenAI API.
        """
        try:
            response = self.client.responses.create(
                model="gpt-4.1-nano",
                input=messages, 
                tools=self.tools,
                max_output_tokens=150,
                temperature=0,
            )
            return response
        
        except Exception as e:
            return "I'm sorry, I'm having trouble processing your request right now."
        
    def generate_embeddings(self, content: str, model: str ="text-embedding-3-large") -> list:
        """
        Generates embeddings for the given text using the OpenAI API.

        Args:
            text (str): The text for which to generate embeddings.

        Returns:
            list: The embeddings generated by the OpenAI API.
        """
        response = self.client.embeddings.create(
            model=model,
            input=content
        )
        return response.data[0].embedding