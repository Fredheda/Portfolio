import os
from dotenv import load_dotenv
from openai import OpenAI
from LLM.LLMClient import LLMClient
_ = load_dotenv()

class OpenAIClient(LLMClient):
    def __init__(self):
        """
        Initializes the OpenAIClient with the given PromptManager.
        """
        self.open_ai_key: str = os.getenv("OPENAI_API_KEY")
        if not self.open_ai_key:
            raise ValueError("OPENAI_API_KEY environment variable not set.")
        
        self.client: OpenAI = OpenAI(api_key=self.open_ai_key)

    def generate_chat_response(self, messages: list, model: str = "gpt-4o-mini") -> str:
        """
        Generates a completion using the OpenAI API based on the user input.

        Args:
            user_input (str): The input provided by the user.

        Returns:
            str: The response generated by the OpenAI API.
        """
        try:
            completion = self.client.chat.completions.create(
                model=model,
                messages=messages,
                max_tokens=150,
                temperature=0,
            )
            response: str = completion.choices[0].message.content.strip()
            return response
        
        except Exception as e:
            return "I'm sorry, I'm having trouble processing your request right now."